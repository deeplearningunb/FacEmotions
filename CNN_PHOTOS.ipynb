{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d2c11a-f4b7-40f7-9250-47ea2ec08912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scikitplot\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, Activation\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55c81b1-1886-42a2-a63c-4fd5a348c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando a path das pastas\n",
    "\n",
    "train_dir = \"./images/train\" #passing the path with training images\n",
    "test_dir = \"./images/validation\"   #passing the path with testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc44f3c-c9cd-4a54-92d2-1ab8df8f8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original size of the image\n",
    "img_size = 48 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "493abbae-7c3e-4d1e-a33a-63e2722461af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processando o pre training set\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9ffbc8-a87f-4eae-9194-15fb1d856972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processando o pre testing set\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                         validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fc853f4-91a3-4881-8d24-4a5c2d8ae283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# depois tem que alterar pra binary pra ver qual performs better\n",
    "train_set = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                    target_size = (img_size,img_size),\n",
    "                                                    batch_size = 32,\n",
    "                                                    color_mode = \"grayscale\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    subset = \"training\"\n",
    "                                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8609b9f4-bab7-4f90-bb47-121080c8b5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1411 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set = validation_datagen.flow_from_directory( directory = test_dir,\n",
    "                                                              target_size = (img_size,img_size),\n",
    "                                                              batch_size = 32,\n",
    "                                                              color_mode = \"grayscale\",\n",
    "                                                              class_mode = \"categorical\",\n",
    "                                                              subset = \"validation\"\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daa476a8-3cfb-43d0-b8f6-e245a6908cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes usado na hora do dense\n",
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6ca0617-08ad-4478-9e40-1d7c7104ff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializing the cnn\n",
    "cnn = Sequential()\n",
    "\n",
    "# First Layer \n",
    "cnn.add(\n",
    "    Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size=(5,5),\n",
    "        input_shape=(img_size, img_size, 1),\n",
    "        activation = 'elu',\n",
    "        name = 'Conv2D_1'\n",
    "    )\n",
    ")\n",
    "\n",
    "cnn.add(BatchNormalization(name='batchnorm_1'))\n",
    "    \n",
    "# Second Layer\n",
    "cnn.add(\n",
    "        Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=(5,5),\n",
    "            activation='elu',\n",
    "            name='conv2d_2'\n",
    "        )\n",
    "    )\n",
    "\n",
    "cnn.add(BatchNormalization(name='batchnorm_2'))\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\n",
    "cnn.add(Dropout(0.4, name='dropout_1'))\n",
    "\n",
    "# Third Layer\n",
    "cnn.add(\n",
    "        Conv2D(\n",
    "            filters=128,\n",
    "            kernel_size=(3,3),\n",
    "            activation='elu',\n",
    "            name='conv2d_3'\n",
    "        )\n",
    "    )\n",
    "\n",
    "cnn.add(BatchNormalization(name='batchnorm_3'))\n",
    "    \n",
    "# Fouth Layer\n",
    "cnn.add(\n",
    "        Conv2D(\n",
    "            filters=128,\n",
    "            kernel_size=(3,3),\n",
    "            activation='elu',\n",
    "            name='conv2d_4'\n",
    "        )\n",
    "    )\n",
    "cnn.add(BatchNormalization(name='batchnorm_4'))\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\n",
    "cnn.add(Dropout(0.4, name='dropout_2'))\n",
    "\n",
    "\n",
    "# flattening\n",
    "cnn.add(Flatten(name='flatten'))\n",
    "    \n",
    "# densing\n",
    "cnn.add(\n",
    "    Dense(\n",
    "        128,\n",
    "        activation='elu',\n",
    "        kernel_initializer='he_normal',\n",
    "        name='dense_1'\n",
    "    )\n",
    ")\n",
    "cnn.add(BatchNormalization(name='batchnorm_7'))\n",
    "\n",
    "cnn.add(Dropout(0.6, name='dropout_4'))\n",
    "\n",
    "cnn.add(\n",
    "    Dense(\n",
    "        num_classes,\n",
    "        activation='softmax',\n",
    "        name='out_layer'\n",
    "    )\n",
    ")\n",
    "\n",
    "cnn.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ada01106-2aa6-41f7-b6c3-ccc3ef2e8ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando GPU pode aumentar a qntd de epochs\n",
    "epochs = 25\n",
    "# dizem que batch size = 32 funciona melhor, mas vi mtts com 64\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28d5f5a6-eeaa-43f7-ba5d-1f9e1e63ce69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D_1 (Conv2D)            (None, 44, 44, 64)        1664      \n",
      "_________________________________________________________________\n",
      "batchnorm_1 (BatchNormalizat (None, 44, 44, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 40, 40, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batchnorm_2 (BatchNormalizat (None, 40, 40, 64)        256       \n",
      "_________________________________________________________________\n",
      "maxpool2d_1 (MaxPooling2D)   (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batchnorm_3 (BatchNormalizat (None, 18, 18, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batchnorm_4 (BatchNormalizat (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "maxpool2d_2 (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "batchnorm_7 (BatchNormalizat (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 1,377,223\n",
      "Trainable params: 1,376,199\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c2d431f-7e12-4815-ac35-52040544e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "901/901 [==============================] - 469s 518ms/step - loss: 2.0158 - accuracy: 0.2938 - val_loss: 1.5289 - val_accuracy: 0.4096\n",
      "Epoch 2/25\n",
      "901/901 [==============================] - 465s 516ms/step - loss: 1.5219 - accuracy: 0.4158 - val_loss: 1.4922 - val_accuracy: 0.4203\n",
      "Epoch 3/25\n",
      "901/901 [==============================] - 471s 522ms/step - loss: 1.4344 - accuracy: 0.4495 - val_loss: 1.4644 - val_accuracy: 0.4444\n",
      "Epoch 4/25\n",
      "901/901 [==============================] - 469s 521ms/step - loss: 1.3825 - accuracy: 0.4709 - val_loss: 1.2730 - val_accuracy: 0.5138\n",
      "Epoch 5/25\n",
      "901/901 [==============================] - 463s 514ms/step - loss: 1.3354 - accuracy: 0.4889 - val_loss: 1.2706 - val_accuracy: 0.5237\n",
      "Epoch 6/25\n",
      "901/901 [==============================] - 484s 537ms/step - loss: 1.3039 - accuracy: 0.5071 - val_loss: 1.3282 - val_accuracy: 0.5273\n",
      "Epoch 7/25\n",
      "901/901 [==============================] - 522s 579ms/step - loss: 1.2709 - accuracy: 0.5194 - val_loss: 1.2256 - val_accuracy: 0.5096\n",
      "Epoch 8/25\n",
      "901/901 [==============================] - 621s 690ms/step - loss: 1.2378 - accuracy: 0.5303 - val_loss: 1.1633 - val_accuracy: 0.5556\n",
      "Epoch 9/25\n",
      "901/901 [==============================] - 540s 599ms/step - loss: 1.2186 - accuracy: 0.5398 - val_loss: 1.2344 - val_accuracy: 0.5542\n",
      "Epoch 10/25\n",
      "901/901 [==============================] - 502s 557ms/step - loss: 1.1936 - accuracy: 0.5503 - val_loss: 1.1278 - val_accuracy: 0.5684\n",
      "Epoch 11/25\n",
      "901/901 [==============================] - 511s 568ms/step - loss: 1.1871 - accuracy: 0.5520 - val_loss: 1.1873 - val_accuracy: 0.5606\n",
      "Epoch 12/25\n",
      "901/901 [==============================] - 495s 549ms/step - loss: 1.1707 - accuracy: 0.5612 - val_loss: 1.1700 - val_accuracy: 0.5422\n",
      "Epoch 13/25\n",
      "901/901 [==============================] - 488s 541ms/step - loss: 1.1529 - accuracy: 0.5684 - val_loss: 1.1340 - val_accuracy: 0.5620\n",
      "Epoch 14/25\n",
      "901/901 [==============================] - 502s 557ms/step - loss: 1.1406 - accuracy: 0.5723 - val_loss: 1.1092 - val_accuracy: 0.5918\n",
      "Epoch 15/25\n",
      "901/901 [==============================] - 549s 610ms/step - loss: 1.1295 - accuracy: 0.5774 - val_loss: 1.1061 - val_accuracy: 0.5783\n",
      "Epoch 16/25\n",
      "901/901 [==============================] - 540s 600ms/step - loss: 1.1189 - accuracy: 0.5805 - val_loss: 1.1225 - val_accuracy: 0.5939\n",
      "Epoch 17/25\n",
      "901/901 [==============================] - 524s 581ms/step - loss: 1.1034 - accuracy: 0.5850 - val_loss: 1.1137 - val_accuracy: 0.5776\n",
      "Epoch 18/25\n",
      "901/901 [==============================] - 475s 527ms/step - loss: 1.0967 - accuracy: 0.5876 - val_loss: 1.0603 - val_accuracy: 0.5960\n",
      "Epoch 19/25\n",
      "901/901 [==============================] - 463s 514ms/step - loss: 1.0885 - accuracy: 0.5954 - val_loss: 1.1157 - val_accuracy: 0.5705\n",
      "Epoch 20/25\n",
      "901/901 [==============================] - 451s 501ms/step - loss: 1.0783 - accuracy: 0.5973 - val_loss: 1.0712 - val_accuracy: 0.6081\n",
      "Epoch 21/25\n",
      "901/901 [==============================] - 451s 500ms/step - loss: 1.0699 - accuracy: 0.5992 - val_loss: 1.0592 - val_accuracy: 0.5925\n",
      "Epoch 22/25\n",
      "901/901 [==============================] - 451s 501ms/step - loss: 1.0604 - accuracy: 0.6038 - val_loss: 1.0492 - val_accuracy: 0.5982\n",
      "Epoch 23/25\n",
      "901/901 [==============================] - 451s 501ms/step - loss: 1.0559 - accuracy: 0.6070 - val_loss: 1.0441 - val_accuracy: 0.6116\n",
      "Epoch 24/25\n",
      "901/901 [==============================] - 450s 500ms/step - loss: 1.0527 - accuracy: 0.6077 - val_loss: 1.0288 - val_accuracy: 0.5996\n",
      "Epoch 25/25\n",
      "901/901 [==============================] - 460s 510ms/step - loss: 1.0443 - accuracy: 0.6073 - val_loss: 1.0413 - val_accuracy: 0.6052\n"
     ]
    }
   ],
   "source": [
    "# training the cnn\n",
    "\n",
    "history = cnn.fit(x = train_set,epochs = epochs,validation_data = validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb98f91b-a6c0-4c54-b698-f4d6ebc2bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save(\"CNN_PHOSTOS_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7571068-ce3b-422b-9621-f4508668ee10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
